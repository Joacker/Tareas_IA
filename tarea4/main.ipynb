{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJYIDa2gTJQZ",
        "outputId": "e903aa36-d15d-4e69-b409-83132eb87b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nes-py==0.2.6\n",
            "  Downloading nes_py-0.2.6.tar.gz (75 kB)\n",
            "     ---------------------------------------- 76.0/76.0 KB 4.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting gym>=0.10.5\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "     ------------------------------------- 696.4/696.4 KB 22.1 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: numpy>=1.14.2 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py==0.2.6) (1.21.2)\n",
            "Requirement already satisfied: pygame>=1.9.3 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py==0.2.6) (2.1.2)\n",
            "Collecting pyglet>=1.3.2\n",
            "  Downloading pyglet-1.5.26-py3-none-any.whl (1.1 MB)\n",
            "     ---------------------------------------- 1.1/1.1 MB 18.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm>=4.19.5 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py==0.2.6) (4.63.0)\n",
            "Collecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.7-py3-none-any.whl (2.7 kB)\n",
            "Collecting importlib-metadata>=4.8.0\n",
            "  Downloading importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.19.5->nes-py==0.2.6) (0.4.4)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
            "Using legacy 'setup.py install' for nes-py, since package 'wheel' is not installed.\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml): started\n",
            "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793136 sha256=4906b9bdf1f53af39f206195d7becf10c6f33bd5cc5d474fa2c15bba1734b46a\n",
            "  Stored in directory: c:\\users\\jfern\\appdata\\local\\pip\\cache\\wheels\\81\\10\\18\\36362eda933f72e09d7c60b5fc9eaf22bf5876ee2450d6da60\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym-notices, zipp, cloudpickle, importlib-metadata, gym, nes-py\n",
            "  Running setup.py install for nes-py: started\n",
            "  Running setup.py install for nes-py: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Running setup.py install for nes-py did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [55 lines of output]\n",
            "      running install\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\n",
            "      creating build\\lib.win-amd64-3.9\n",
            "      creating build\\lib.win-amd64-3.9\\nes_py\n",
            "      copying nes_py\\nes_env.py -> build\\lib.win-amd64-3.9\\nes_py\n",
            "      copying nes_py\\_image_viewer.py -> build\\lib.win-amd64-3.9\\nes_py\n",
            "      copying nes_py\\__init__.py -> build\\lib.win-amd64-3.9\\nes_py\n",
            "      creating build\\lib.win-amd64-3.9\\nes_py\\spaces\n",
            "      copying nes_py\\spaces\\bitmap.py -> build\\lib.win-amd64-3.9\\nes_py\\spaces\n",
            "      copying nes_py\\spaces\\__init__.py -> build\\lib.win-amd64-3.9\\nes_py\\spaces\n",
            "      creating build\\lib.win-amd64-3.9\\nes_py\\tests\n",
            "      copying nes_py\\tests\\test_nes_env.py -> build\\lib.win-amd64-3.9\\nes_py\\tests\n",
            "      copying nes_py\\tests\\__init__.py -> build\\lib.win-amd64-3.9\\nes_py\\tests\n",
            "      creating build\\lib.win-amd64-3.9\\nes_py\\_app\n",
            "      copying nes_py\\_app\\cli.py -> build\\lib.win-amd64-3.9\\nes_py\\_app\n",
            "      copying nes_py\\_app\\play.py -> build\\lib.win-amd64-3.9\\nes_py\\_app\n",
            "      copying nes_py\\_app\\play_human.py -> build\\lib.win-amd64-3.9\\nes_py\\_app\n",
            "      copying nes_py\\_app\\__init__.py -> build\\lib.win-amd64-3.9\\nes_py\\_app\n",
            "      running build_ext\n",
            "      building 'nes_py/laines/build/lib_nes_env' extension\n",
            "      creating build\\temp.win-amd64-3.9\n",
            "      creating build\\temp.win-amd64-3.9\\Release\n",
            "      creating build\\temp.win-amd64-3.9\\Release\\nes_py\n",
            "      creating build\\temp.win-amd64-3.9\\Release\\nes_py\\laines\n",
            "      creating build\\temp.win-amd64-3.9\\Release\\nes_py\\laines\\mappers\n",
            "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ines_py/laines/include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt /EHsc /Tpnes_py/laines/mappers\\mapper1.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\nes_py/laines/mappers\\mapper1.obj -O3 -march=native -std=c++14\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-O3'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-march=native'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-std=c++14'\n",
            "      mapper1.cpp\n",
            "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ines_py/laines/include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt /EHsc /Tpnes_py/laines/mappers\\mapper2.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\nes_py/laines/mappers\\mapper2.obj -O3 -march=native -std=c++14\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-O3'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-march=native'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-std=c++14'\n",
            "      mapper2.cpp\n",
            "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ines_py/laines/include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt /EHsc /Tpnes_py/laines/mappers\\mapper3.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\nes_py/laines/mappers\\mapper3.obj -O3 -march=native -std=c++14\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-O3'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-march=native'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-std=c++14'\n",
            "      mapper3.cpp\n",
            "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ines_py/laines/include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt /EHsc /Tpnes_py/laines/mappers\\mapper4.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\nes_py/laines/mappers\\mapper4.obj -O3 -march=native -std=c++14\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-O3'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-march=native'\n",
            "      cl : L¡nea de comandos warning D9002 : se omite la opci¢n desconocida '-std=c++14'\n",
            "      mapper4.cpp\n",
            "      nes_py/laines/include\\cpu.hpp(25): warning C4805: '|': combinaci¢n no segura del tipo 'bool' y el tipo 'int' en la operaci¢n\n",
            "      nes_py/laines/mappers\\mapper4.cpp(76): error C2146: error de sintaxis: falta ')' delante del identificador 'and'\n",
            "      nes_py/laines/mappers\\mapper4.cpp(76): error C2065: 'and': identificador no declarado\n",
            "      nes_py/laines/mappers\\mapper4.cpp(76): error C2146: error de sintaxis: falta ';' delante del identificador 'irqCounter'\n",
            "      nes_py/laines/mappers\\mapper4.cpp(76): error C2059: error de sintaxis: ')'\n",
            "      nes_py/laines/mappers\\mapper4.cpp(77): error C2143: error de sintaxis: falta ';' delante de 'CPU::set_irq'\n",
            "      nes_py/laines/mappers\\mapper4.cpp(76): warning C4553: \"==\": el resultado de la expresi¢n no se usa. ¨Quiso decir \"=\"?\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2017\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.16.27023\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: legacy-install-failure\n",
            "\n",
            "× Encountered error while trying to install package.\n",
            "╰─> nes-py\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for output from the failure.\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gym-super-mario-bros\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "     ------------------------------------- 199.1/199.1 KB 12.6 MB/s eta 0:00:00\n",
            "Collecting nes-py>=8.1.4\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "     ---------------------------------------- 77.7/77.7 KB 4.2 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: gym>=0.17.2 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.21.2)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "     ---------------------------------------- 1.1/1.1 MB 18.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.63.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (0.0.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (4.11.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.48.2->nes-py>=8.1.4->gym-super-mario-bros) (0.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (3.8.0)\n",
            "Using legacy 'setup.py install' for nes-py, since package 'wheel' is not installed.\n",
            "Installing collected packages: pyglet, nes-py, gym-super-mario-bros\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.26\n",
            "    Uninstalling pyglet-1.5.26:\n",
            "      Successfully uninstalled pyglet-1.5.26\n",
            "  Running setup.py install for nes-py: started\n",
            "  Running setup.py install for nes-py: finished with status 'done'\n",
            "Successfully installed gym-super-mario-bros-7.4.0 nes-py-8.2.1 pyglet-1.5.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
            "\"apt-get\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "\"apt-get\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "\"apt\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
            "     --------------------------------------- 35.6/35.6 MB 18.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jfern\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.21.2)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.6.0.66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\jfern\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install nes-py==0.2.6\n",
        "!pip install gym-super-mario-bros\n",
        "!apt-get update\n",
        "!apt-get install ffmpeg libsm6 libxext6  -y\n",
        "!apt install -y libgl1-mesa-glx\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxptdo-jT0hn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from tqdm import tqdm\n",
        "import pickle \n",
        "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
        "import gym\n",
        "import numpy as np\n",
        "import collections \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W12QYhSgUrv7"
      },
      "outputs": [],
      "source": [
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Downsamples image to 84x84\n",
        "    Greyscales image\n",
        "\n",
        "    Returns numpy array\n",
        "    \"\"\"\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 240 * 256 * 3:\n",
        "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env):\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    env = ScaledFloatFrame(env)\n",
        "    return JoypadSpace(env, RIGHT_ONLY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ5-gK32Uv06"
      },
      "outputs": [],
      "source": [
        "class DQNSolver(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQNSolver, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "    \n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)\n",
        "    \n",
        "\n",
        "class DQNAgent:\n",
        "\n",
        "    def __init__(self, state_space, action_space, max_memory_size, batch_size, gamma, lr,\n",
        "                 dropout, exploration_max, exploration_min, exploration_decay, double_dq, pretrained):\n",
        "\n",
        "        # Define DQN Layers\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.double_dq = double_dq\n",
        "        self.pretrained = pretrained\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        if self.double_dq:  \n",
        "            self.local_net = DQNSolver(state_space, action_space).to(self.device)\n",
        "            self.target_net = DQNSolver(state_space, action_space).to(self.device)\n",
        "            \n",
        "            if self.pretrained:\n",
        "                self.local_net.load_state_dict(torch.load(\"dq1.pt\", map_location=torch.device(self.device)))\n",
        "                self.target_net.load_state_dict(torch.load(\"dq2.pt\", map_location=torch.device(self.device)))\n",
        "                    \n",
        "            self.optimizer = torch.optim.Adam(self.local_net.parameters(), lr=lr)\n",
        "            self.copy = 5000  # Copy the local model weights into the target network every 5000 steps\n",
        "            self.step = 0\n",
        "        else:  \n",
        "            self.dqn = DQNSolver(state_space, action_space).to(self.device)\n",
        "            \n",
        "            if self.pretrained:\n",
        "                self.dqn.load_state_dict(torch.load(\"dq.pt\", map_location=torch.device(self.device)))\n",
        "            self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=lr)\n",
        "\n",
        "        # Create memory\n",
        "        self.max_memory_size = max_memory_size\n",
        "        if self.pretrained:\n",
        "            self.STATE_MEM = torch.load(\"STATE_MEM.pt\")\n",
        "            self.ACTION_MEM = torch.load(\"ACTION_MEM.pt\")\n",
        "            self.REWARD_MEM = torch.load(\"REWARD_MEM.pt\")\n",
        "            self.STATE2_MEM = torch.load(\"STATE2_MEM.pt\")\n",
        "            self.DONE_MEM = torch.load(\"DONE_MEM.pt\")\n",
        "            with open(\"ending_position.pkl\", 'rb') as f:\n",
        "                self.ending_position = pickle.load(f)\n",
        "            with open(\"num_in_queue.pkl\", 'rb') as f:\n",
        "                self.num_in_queue = pickle.load(f)\n",
        "        else:\n",
        "            self.STATE_MEM = torch.zeros(max_memory_size, *self.state_space)\n",
        "            self.ACTION_MEM = torch.zeros(max_memory_size, 1)\n",
        "            self.REWARD_MEM = torch.zeros(max_memory_size, 1)\n",
        "            self.STATE2_MEM = torch.zeros(max_memory_size, *self.state_space)\n",
        "            self.DONE_MEM = torch.zeros(max_memory_size, 1)\n",
        "            self.ending_position = 0\n",
        "            self.num_in_queue = 0\n",
        "        \n",
        "        self.memory_sample_size = batch_size\n",
        "        \n",
        "        # Learning parameters\n",
        "        self.gamma = gamma\n",
        "        self.l1 = nn.SmoothL1Loss().to(self.device) # Also known as Huber loss\n",
        "        self.exploration_max = exploration_max\n",
        "        self.exploration_rate = exploration_max\n",
        "        self.exploration_min = exploration_min\n",
        "        self.exploration_decay = exploration_decay\n",
        "\n",
        "    def remember(self, state, action, reward, state2, done):\n",
        "        self.STATE_MEM[self.ending_position] = state.float()\n",
        "        self.ACTION_MEM[self.ending_position] = action.float()\n",
        "        self.REWARD_MEM[self.ending_position] = reward.float()\n",
        "        self.STATE2_MEM[self.ending_position] = state2.float()\n",
        "        self.DONE_MEM[self.ending_position] = done.float()\n",
        "        self.ending_position = (self.ending_position + 1) % self.max_memory_size  # FIFO tensor\n",
        "        self.num_in_queue = min(self.num_in_queue + 1, self.max_memory_size)\n",
        "        \n",
        "    def recall(self):\n",
        "        # Randomly sample 'batch size' experiences\n",
        "        idx = random.choices(range(self.num_in_queue), k=self.memory_sample_size)\n",
        "        \n",
        "        STATE = self.STATE_MEM[idx]\n",
        "        ACTION = self.ACTION_MEM[idx]\n",
        "        REWARD = self.REWARD_MEM[idx]\n",
        "        STATE2 = self.STATE2_MEM[idx]\n",
        "        DONE = self.DONE_MEM[idx]\n",
        "        \n",
        "        return STATE, ACTION, REWARD, STATE2, DONE\n",
        "\n",
        "    def act(self, state):\n",
        "        # Epsilon-greedy action\n",
        "        \n",
        "        if self.double_dq:\n",
        "            self.step += 1\n",
        "        if random.random() < self.exploration_rate:  \n",
        "            return torch.tensor([[random.randrange(self.action_space)]])\n",
        "        if self.double_dq:\n",
        "            # Local net is used for the policy\n",
        "            return torch.argmax(self.local_net(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
        "        else:\n",
        "            return torch.argmax(self.dqn(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
        "\n",
        "    def copy_model(self):\n",
        "        # Copy local net weights into target net\n",
        "        \n",
        "        self.target_net.load_state_dict(self.local_net.state_dict())\n",
        "    \n",
        "    def experience_replay(self):\n",
        "        \n",
        "        if self.double_dq and self.step % self.copy == 0:\n",
        "            self.copy_model()\n",
        "\n",
        "        if self.memory_sample_size > self.num_in_queue:\n",
        "            return\n",
        "\n",
        "        STATE, ACTION, REWARD, STATE2, DONE = self.recall()\n",
        "        STATE = STATE.to(self.device)\n",
        "        ACTION = ACTION.to(self.device)\n",
        "        REWARD = REWARD.to(self.device)\n",
        "        STATE2 = STATE2.to(self.device)\n",
        "        DONE = DONE.to(self.device)\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        if self.double_dq:\n",
        "            # Double Q-Learning target is Q*(S, A) <- r + γ max_a Q_target(S', a)\n",
        "            target = REWARD + torch.mul((self.gamma * \n",
        "                                        self.target_net(STATE2).max(1).values.unsqueeze(1)), \n",
        "                                        1 - DONE)\n",
        "\n",
        "            current = self.local_net(STATE).gather(1, ACTION.long()) # Local net approximation of Q-value\n",
        "        else:\n",
        "            # Q-Learning target is Q*(S, A) <- r + γ max_a Q(S', a) \n",
        "            target = REWARD + torch.mul((self.gamma * \n",
        "                                        self.dqn(STATE2).max(1).values.unsqueeze(1)), \n",
        "                                        1 - DONE)\n",
        "                \n",
        "            current = self.dqn(STATE).gather(1, ACTION.long())\n",
        "        \n",
        "        loss = self.l1(current, target)\n",
        "        loss.backward() # Compute gradients\n",
        "        self.optimizer.step() # Backpropagate error\n",
        "\n",
        "        self.exploration_rate *= self.exploration_decay\n",
        "        \n",
        "        # Makes sure that exploration rate is always at least 'exploration min'\n",
        "        self.exploration_rate = max(self.exploration_rate, self.exploration_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p90AVZ-HUxvB"
      },
      "outputs": [],
      "source": [
        "def vectorize_action(action, action_space):\n",
        "    # Given a scalar action, return a one-hot encoded action\n",
        "    \n",
        "    return [0 for _ in range(action)] + [1] + [0 for _ in range(action + 1, action_space)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXRzzUwUzIQ"
      },
      "outputs": [],
      "source": [
        "def show_state(env, ep=0, info=\"\"):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.title(\"Episode: %d %s\" % (ep, info))\n",
        "    plt.axis('off')\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO4fKG4VU2u5",
        "outputId": "9f0fcc3c-abcf-4ec1-b842-08fcd3dffea8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  0%|          | 1/10000 [00:03<8:49:41,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 1 is 240.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/10000 [00:11<16:33:09,  5.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 2 is 244.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/10000 [00:53<62:29:14, 22.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 3 is 554.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 4/10000 [00:58<43:31:41, 15.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 4 is 231.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 5/10000 [01:46<75:40:47, 27.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 5 is 540.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 6/10000 [01:51<54:39:59, 19.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 6 is 246.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 7/10000 [01:55<40:55:03, 14.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 7 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 8/10000 [01:59<31:16:56, 11.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 8 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 9/10000 [02:03<24:57:54,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 9 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 10/10000 [02:07<20:35:05,  7.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 10 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 11/10000 [02:11<17:38:55,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 11 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 12/10000 [02:15<15:34:34,  5.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 12 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 13/10000 [02:19<14:07:27,  5.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 13 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 14/10000 [02:23<13:10:55,  4.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 14 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 15/10000 [02:27<12:29:55,  4.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 15 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 16/10000 [02:31<11:59:50,  4.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 16 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 17/10000 [02:34<11:29:20,  4.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 17 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 18/10000 [02:38<11:09:56,  4.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 18 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 19/10000 [02:42<11:05:07,  4.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 19 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 20/10000 [02:46<11:03:19,  3.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 20 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 21/10000 [02:50<10:52:42,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 21 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 22/10000 [02:54<10:43:55,  3.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 22 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 23/10000 [02:57<10:44:36,  3.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 23 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 24/10000 [03:01<10:41:26,  3.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 24 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 25/10000 [03:05<10:50:35,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 25 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 26/10000 [03:09<10:52:25,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 26 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 27/10000 [03:13<10:57:02,  3.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 27 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 28/10000 [03:17<10:51:15,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 28 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 29/10000 [03:21<10:48:34,  3.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 29 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 30/10000 [03:25<10:45:02,  3.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 30 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 31/10000 [03:29<10:49:35,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 31 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 32/10000 [03:33<10:47:11,  3.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 32 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 33/10000 [03:37<10:54:28,  3.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 33 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 34/10000 [03:41<11:14:41,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 34 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 35/10000 [03:45<11:32:33,  4.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 35 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 36/10000 [03:49<11:24:07,  4.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 36 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 37/10000 [03:53<11:17:54,  4.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 37 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 38/10000 [03:57<11:14:42,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 38 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 39/10000 [04:01<11:02:50,  3.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 39 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 40/10000 [04:05<11:06:07,  4.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 40 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 41/10000 [04:10<11:22:51,  4.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 41 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 42/10000 [04:14<11:20:54,  4.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 42 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 43/10000 [04:18<11:14:06,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 43 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 44/10000 [04:22<11:03:26,  4.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 44 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 45/10000 [04:25<10:56:46,  3.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 45 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 46/10000 [04:29<10:58:07,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 46 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 47/10000 [04:33<10:50:51,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 47 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 48/10000 [04:37<10:51:13,  3.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 48 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 49/10000 [04:41<10:54:34,  3.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 49 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 50/10000 [04:45<10:58:04,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 50 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 51/10000 [04:49<10:51:33,  3.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 51 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 52/10000 [04:53<10:52:12,  3.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 52 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 53/10000 [05:04<16:22:14,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 53 is 632.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 54/10000 [05:08<14:45:28,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 54 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 55/10000 [05:12<13:38:10,  4.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 55 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 56/10000 [05:15<12:49:46,  4.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 56 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 57/10000 [05:19<12:17:25,  4.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 57 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 58/10000 [05:24<12:00:35,  4.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 58 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 59/10000 [05:27<11:35:06,  4.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 59 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 60/10000 [05:31<11:23:40,  4.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 60 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 61/10000 [05:35<11:21:40,  4.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 61 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 62/10000 [05:40<11:20:47,  4.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 62 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 63/10000 [05:43<11:07:39,  4.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 63 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 64/10000 [05:47<10:57:46,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 64 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 65/10000 [05:51<11:11:04,  4.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 65 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 66/10000 [05:56<11:09:08,  4.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 66 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 67/10000 [06:15<24:15:40,  8.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 67 is 640.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 68/10000 [06:20<20:31:09,  7.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 68 is 253.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 69/10000 [06:24<17:57:43,  6.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 69 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 70/10000 [06:44<29:10:57, 10.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 70 is 639.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 71/10000 [06:48<23:36:44,  8.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 71 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 72/10000 [06:52<19:52:42,  7.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 72 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 73/10000 [07:03<22:38:53,  8.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 73 is 632.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 74/10000 [07:14<24:56:14,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 74 is 637.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 75/10000 [07:18<20:47:51,  7.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 75 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 76/10000 [07:21<17:44:06,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 76 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 77/10000 [07:25<15:32:37,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 77 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 78/10000 [07:29<14:04:12,  5.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 78 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 79/10000 [07:41<19:22:43,  7.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 79 is 633.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 80/10000 [07:45<17:05:42,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 80 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 81/10000 [07:49<15:27:10,  5.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 81 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 82/10000 [07:53<14:06:52,  5.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 82 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 83/10000 [08:04<18:57:59,  6.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 83 is 637.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 84/10000 [08:08<16:55:53,  6.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 84 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 85/10000 [08:20<21:08:42,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 85 is 652.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 86/10000 [08:40<31:40:23, 11.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 86 is 815.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 87/10000 [08:44<25:41:04,  9.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 87 is 253.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 88/10000 [08:57<27:59:09, 10.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 88 is 632.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 89/10000 [09:17<36:48:45, 13.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 89 is 626.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 90/10000 [09:45<48:22:26, 17.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 90 is 1339.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 91/10000 [09:50<37:51:19, 13.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 91 is 240.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 92/10000 [10:31<60:55:33, 22.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 92 is 577.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 93/10000 [10:56<63:13:43, 22.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 93 is 808.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 94/10000 [11:15<59:26:20, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 94 is 789.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 95/10000 [11:26<51:12:09, 18.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 95 is 637.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 96/10000 [11:37<44:29:34, 16.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 96 is 653.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 97/10000 [11:48<40:33:36, 14.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 97 is 652.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 98/10000 [12:06<42:50:16, 15.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 98 is 1049.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 99/10000 [12:18<40:32:36, 14.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 99 is 617.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 100/10000 [12:29<37:11:00, 13.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 100 is 652.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 101/10000 [12:48<41:13:50, 14.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 101 is 1054.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 102/10000 [12:58<37:27:51, 13.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 102 is 613.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 103/10000 [13:18<42:19:03, 15.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 103 is 1049.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 104/10000 [13:39<47:34:05, 17.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 104 is 814.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 105/10000 [14:00<50:41:31, 18.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 105 is 639.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 106/10000 [14:05<39:07:58, 14.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 106 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 107/10000 [14:25<44:09:29, 16.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 107 is 815.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 108/10000 [14:30<34:50:49, 12.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 108 is 242.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 109/10000 [14:59<48:14:20, 17.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 109 is 803.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 110/10000 [15:10<43:01:20, 15.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 110 is 636.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 111/10000 [15:35<50:20:26, 18.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 111 is 1437.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 112/10000 [15:57<53:34:10, 19.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 112 is 1344.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 113/10000 [16:02<41:20:08, 15.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 113 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 114/10000 [16:05<32:10:23, 11.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 114 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 115/10000 [16:18<32:44:59, 11.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 115 is 620.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 116/10000 [16:22<26:19:51,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 116 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 117/10000 [16:26<21:33:50,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 117 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 118/10000 [16:30<18:22:43,  6.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 118 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 119/10000 [16:34<16:13:37,  5.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 119 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 120/10000 [16:58<31:12:15, 11.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 120 is 1436.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 121/10000 [17:22<41:34:56, 15.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 121 is 1343.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 122/10000 [17:26<32:17:08, 11.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 122 is 245.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 123/10000 [17:30<26:01:38,  9.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 123 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 124/10000 [17:34<21:30:52,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 124 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 125/10000 [17:54<31:40:09, 11.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 125 is 640.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 126/10000 [17:58<25:24:23,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 126 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 127/10000 [18:02<20:57:50,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 127 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 128/10000 [18:19<28:31:23, 10.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 128 is 1057.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 129/10000 [19:19<69:29:24, 25.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 129 is 1388.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 130/10000 [19:23<51:59:05, 18.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 130 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 131/10000 [19:53<60:37:36, 22.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 131 is 1135.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 132/10000 [20:34<76:17:57, 27.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 132 is 1128.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 133/10000 [20:56<71:44:17, 26.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 133 is 1345.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 134/10000 [21:27<75:56:17, 27.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 134 is 1334.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 135/10000 [21:39<62:28:28, 22.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 135 is 639.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 136/10000 [21:43<46:52:02, 17.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 136 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 137/10000 [22:06<52:08:16, 19.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 137 is 619.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 138/10000 [22:24<51:04:10, 18.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 138 is 1056.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 139/10000 [22:28<39:15:28, 14.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 139 is 237.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 140/10000 [22:49<44:23:53, 16.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 140 is 815.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 141/10000 [23:14<51:33:34, 18.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 141 is 729.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 142/10000 [23:25<45:06:27, 16.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 142 is 636.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 143/10000 [23:38<42:45:03, 15.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 143 is 608.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 144/10000 [23:55<43:52:00, 16.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 144 is 1048.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 145/10000 [24:23<53:14:05, 19.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 145 is 1427.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 146/10000 [24:27<40:30:45, 14.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 146 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 147/10000 [24:46<44:28:49, 16.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 147 is 730.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 148/10000 [25:07<48:23:23, 17.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 148 is 742.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 149/10000 [25:39<60:06:33, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 149 is 1421.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 150/10000 [26:13<70:02:23, 25.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 150 is 1132.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 151/10000 [26:40<70:33:12, 25.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 151 is 1045.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 152/10000 [27:01<66:40:24, 24.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 152 is 1440.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 153/10000 [27:27<68:43:54, 25.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 153 is 1339.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 154/10000 [27:37<55:52:40, 20.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 154 is 622.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 155/10000 [28:00<57:48:15, 21.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 155 is 1433.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 156/10000 [28:23<59:14:38, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 156 is 1330.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 157/10000 [28:42<57:41:02, 21.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 157 is 817.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 158/10000 [29:19<70:10:02, 25.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 158 is 1308.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 159/10000 [29:53<77:25:07, 28.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 159 is 1421.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 160/10000 [30:17<73:23:07, 26.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 160 is 1332.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 161/10000 [30:37<67:53:48, 24.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 161 is 816.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 162/10000 [31:02<67:53:51, 24.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 162 is 1432.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 163/10000 [31:21<63:28:25, 23.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 163 is 622.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 164/10000 [31:25<47:43:46, 17.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 164 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 165/10000 [31:29<36:37:34, 13.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 165 is 245.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 166/10000 [31:33<28:55:57, 10.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 166 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 167/10000 [32:12<52:01:14, 19.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 167 is 790.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 168/10000 [32:40<59:07:57, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 168 is 1432.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 169/10000 [32:44<44:42:14, 16.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 169 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 170/10000 [32:48<35:10:33, 12.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 170 is 235.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 171/10000 [32:53<28:03:21, 10.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 171 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 172/10000 [33:18<40:13:05, 14.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 172 is 1433.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 173/10000 [33:54<58:13:43, 21.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 173 is 1687.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 174/10000 [33:59<44:15:28, 16.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 174 is 241.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 175/10000 [34:18<46:46:40, 17.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 175 is 816.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 176/10000 [34:41<51:27:03, 18.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 176 is 1439.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 177/10000 [34:54<46:29:12, 17.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 177 is 731.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 178/10000 [35:04<40:51:59, 14.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 178 is 614.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 179/10000 [35:31<50:44:11, 18.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 179 is 1035.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 180/10000 [35:36<39:22:40, 14.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 180 is 243.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 181/10000 [35:47<37:04:04, 13.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 181 is 616.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 182/10000 [35:58<34:35:39, 12.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 182 is 653.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 183/10000 [36:02<27:23:32, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 183 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 184/10000 [36:13<28:37:44, 10.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 184 is 609.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 185/10000 [36:26<30:03:04, 11.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 185 is 608.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 186/10000 [37:19<64:26:15, 23.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 186 is 1105.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 187/10000 [37:35<58:36:52, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 187 is 1072.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 188/10000 [37:39<44:09:07, 16.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 188 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 189/10000 [38:00<48:30:40, 17.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 189 is 1044.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 190/10000 [38:30<58:20:11, 21.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 190 is 1695.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 191/10000 [38:39<48:17:18, 17.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 191 is 608.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 192/10000 [38:53<44:50:36, 16.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 192 is 612.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 193/10000 [38:57<34:52:56, 12.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 193 is 238.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 194/10000 [39:01<27:54:08, 10.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 194 is 237.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 195/10000 [39:32<44:39:31, 16.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 195 is 1422.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 196/10000 [39:59<53:04:10, 19.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 196 is 1344.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 197/10000 [40:09<45:14:57, 16.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 197 is 633.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 198/10000 [40:13<35:28:44, 13.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 198 is 238.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 199/10000 [40:17<28:04:51, 10.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 199 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 200/10000 [40:30<29:59:50, 11.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 200 is 619.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 201/10000 [40:34<24:16:29,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 201 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 202/10000 [40:54<33:13:37, 12.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 202 is 816.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 203/10000 [41:20<44:15:23, 16.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 203 is 1037.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 204/10000 [41:41<48:35:57, 17.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 204 is 813.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 205/10000 [42:16<62:35:06, 23.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 205 is 795.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 206/10000 [42:20<47:01:05, 17.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 206 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 207/10000 [42:56<61:40:08, 22.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 207 is 1695.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 208/10000 [43:21<63:45:10, 23.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 208 is 1430.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 209/10000 [43:33<54:42:18, 20.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 209 is 623.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 210/10000 [43:47<49:20:26, 18.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 210 is 616.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 211/10000 [44:11<54:44:13, 20.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 211 is 1429.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 212/10000 [44:39<61:11:47, 22.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 212 is 628.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 213/10000 [45:08<65:53:39, 24.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 213 is 1853.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 214/10000 [45:12<49:21:03, 18.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 214 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 215/10000 [45:40<57:41:05, 21.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 215 is 804.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 216/10000 [45:59<55:32:19, 20.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 216 is 1050.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 217/10000 [46:03<42:29:02, 15.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 217 is 238.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 218/10000 [46:12<37:08:59, 13.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 218 is 606.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 219/10000 [46:33<42:44:12, 15.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 219 is 1436.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 220/10000 [46:37<33:29:20, 12.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 220 is 247.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 221/10000 [46:41<26:39:44,  9.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 221 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 222/10000 [47:03<36:54:31, 13.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 222 is 1150.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 223/10000 [47:39<54:46:00, 20.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 223 is 1335.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 224/10000 [47:47<45:12:50, 16.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 224 is 610.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 225/10000 [47:51<34:46:02, 12.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 225 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 226/10000 [48:22<49:28:18, 18.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 226 is 1845.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 227/10000 [49:05<69:39:14, 25.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 227 is 1670.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 228/10000 [49:09<51:52:35, 19.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 228 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 229/10000 [49:32<55:04:52, 20.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 229 is 811.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 230/10000 [49:36<41:47:41, 15.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 230 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 231/10000 [49:49<39:41:45, 14.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 231 is 603.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 232/10000 [50:14<48:36:35, 17.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 232 is 1037.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 233/10000 [50:40<55:08:12, 20.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 233 is 1428.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 234/10000 [51:05<58:23:01, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 234 is 810.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 235/10000 [51:24<56:31:01, 20.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 235 is 641.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 236/10000 [51:28<42:43:42, 15.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 236 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 237/10000 [51:47<45:35:56, 16.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 237 is 770.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 238/10000 [52:23<61:06:19, 22.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 238 is 1031.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 239/10000 [52:40<56:37:01, 20.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 239 is 1049.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 240/10000 [52:50<48:00:28, 17.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 240 is 612.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 241/10000 [52:54<36:56:18, 13.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 241 is 246.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 242/10000 [52:58<29:04:03, 10.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 242 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 243/10000 [53:03<24:08:12,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 243 is 245.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 244/10000 [53:29<38:07:54, 14.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 244 is 757.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 245/10000 [53:33<29:51:20, 11.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 245 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 246/10000 [53:37<24:03:17,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 246 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 247/10000 [53:57<33:06:14, 12.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 247 is 1055.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 248/10000 [54:26<46:22:01, 17.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 248 is 595.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 249/10000 [54:29<35:34:16, 13.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 249 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 250/10000 [58:38<226:45:37, 83.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 250 is 725.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 251/10000 [59:00<176:57:52, 65.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 251 is 770.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 252/10000 [59:04<126:59:33, 46.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 252 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 253/10000 [59:08<92:15:39, 34.08s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 253 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 254/10000 [59:48<97:01:31, 35.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 254 is 1316.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 255/10000 [59:52<71:21:43, 26.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 255 is 238.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 256/10000 [1:00:18<70:25:18, 26.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 256 is 1044.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 257/10000 [1:00:22<52:26:27, 19.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 257 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 258/10000 [1:00:25<39:49:59, 14.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 258 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 259/10000 [1:00:47<45:41:13, 16.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 259 is 813.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 260/10000 [1:00:58<40:17:33, 14.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 260 is 627.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 261/10000 [1:01:02<31:33:33, 11.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 261 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 262/10000 [1:01:36<49:58:05, 18.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 262 is 1035.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 263/10000 [1:01:40<38:21:30, 14.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 263 is 250.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 264/10000 [1:02:08<49:19:53, 18.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 264 is 1040.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 265/10000 [1:02:22<45:32:02, 16.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 265 is 627.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 266/10000 [1:02:31<39:42:31, 14.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 266 is 617.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 267/10000 [1:02:35<30:55:08, 11.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 267 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 268/10000 [1:02:39<24:53:20,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 268 is 246.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 269/10000 [1:02:51<27:09:42, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 269 is 623.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 270/10000 [1:03:24<45:38:46, 16.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 270 is 1424.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 271/10000 [1:03:28<35:29:51, 13.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 271 is 241.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 272/10000 [1:04:05<54:29:23, 20.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 272 is 1415.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 273/10000 [1:04:26<55:08:39, 20.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 273 is 604.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 274/10000 [1:04:50<58:28:56, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 274 is 1341.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 275/10000 [1:05:01<49:40:02, 18.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 275 is 635.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 276/10000 [1:05:05<37:54:25, 14.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 276 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 277/10000 [1:05:22<40:29:44, 14.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 277 is 613.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 278/10000 [1:05:46<47:12:14, 17.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 278 is 1146.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 279/10000 [1:06:06<49:34:11, 18.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 279 is 1067.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 280/10000 [1:06:30<54:22:40, 20.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 280 is 1038.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 281/10000 [1:06:40<46:06:55, 17.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 281 is 612.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 282/10000 [1:06:44<35:22:25, 13.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 282 is 248.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 283/10000 [1:07:20<53:55:41, 19.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 283 is 1915.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 284/10000 [1:07:24<41:01:04, 15.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 284 is 251.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 285/10000 [1:07:28<31:50:18, 11.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 285 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 286/10000 [1:07:32<25:25:35,  9.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 286 is 249.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 287/10000 [1:07:42<26:25:12,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 287 is 611.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 288/10000 [1:07:46<21:38:06,  8.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 288 is 252.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 289/10000 [1:08:09<33:50:46, 12.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 289 is 811.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 290/10000 [1:08:13<26:51:42,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward after episode 290 is 248.0\n"
          ]
        }
      ],
      "source": [
        "def run(training_mode, pretrained):\n",
        "   \n",
        "    env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
        "    env = make_env(env)  # Wraps the environment so that frames are grayscale \n",
        "    observation_space = env.observation_space.shape\n",
        "    action_space = env.action_space.n\n",
        "    agent = DQNAgent(state_space=observation_space,\n",
        "                     action_space=action_space,\n",
        "                     max_memory_size=30000,\n",
        "                     batch_size=32,\n",
        "                     gamma=0.90,\n",
        "                     lr=0.00025,\n",
        "                     dropout=0.,\n",
        "                     exploration_max=1.0,\n",
        "                     exploration_min=0.02,\n",
        "                     exploration_decay=0.99,\n",
        "                     double_dq=True,\n",
        "                     pretrained=pretrained)\n",
        "    \n",
        "    num_episodes = 10000\n",
        "    env.reset()\n",
        "    total_rewards = []\n",
        "    \n",
        "    for ep_num in tqdm(range(num_episodes)):\n",
        "        state = env.reset()\n",
        "        state = torch.Tensor([state])\n",
        "        total_reward = 0\n",
        "        steps = 0\n",
        "        while True:\n",
        "            if not training_mode:\n",
        "                show_state(env, ep_num)\n",
        "            action = agent.act(state)\n",
        "            steps += 1\n",
        "            \n",
        "            state_next, reward, terminal, info = env.step(int(action[0]))\n",
        "            total_reward += reward\n",
        "            state_next = torch.Tensor([state_next])\n",
        "            reward = torch.tensor([reward]).unsqueeze(0)\n",
        "            \n",
        "            terminal = torch.tensor([int(terminal)]).unsqueeze(0)\n",
        "            \n",
        "            if training_mode:\n",
        "                agent.remember(state, action, reward, state_next, terminal)\n",
        "                agent.experience_replay()\n",
        "            \n",
        "            state = state_next\n",
        "            if terminal:\n",
        "                break\n",
        "        \n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "        print(\"Total reward after episode {} is {}\".format(ep_num + 1, total_rewards[-1]))\n",
        "        num_episodes += 1      \n",
        "    \n",
        "    if training_mode:\n",
        "        with open(\"ending_position.pkl\", \"wb\") as f:\n",
        "            pickle.dump(agent.ending_position, f)\n",
        "        with open(\"num_in_queue.pkl\", \"wb\") as f:\n",
        "            pickle.dump(agent.num_in_queue, f)\n",
        "        with open(\"total_rewards.pkl\", \"wb\") as f:\n",
        "            pickle.dump(total_rewards, f)\n",
        "        if agent.double_dq:\n",
        "            torch.save(agent.local_net.state_dict(), \"dq1.pt\")\n",
        "            torch.save(agent.target_net.state_dict(), \"dq2.pt\")\n",
        "        else:\n",
        "            torch.save(agent.dqn.state_dict(), \"dq.pt\")  \n",
        "        torch.save(agent.STATE_MEM,  \"STATE_MEM.pt\")\n",
        "        torch.save(agent.ACTION_MEM, \"ACTION_MEM.pt\")\n",
        "        torch.save(agent.REWARD_MEM, \"REWARD_MEM.pt\")\n",
        "        torch.save(agent.STATE2_MEM, \"STATE2_MEM.pt\")\n",
        "        torch.save(agent.DONE_MEM,   \"DONE_MEM.pt\")\n",
        "    \n",
        "    env.close()\n",
        "    \n",
        "    if num_episodes > 500:\n",
        "        plt.title(\"Episodes trained vs. Average Rewards (per 500 eps)\")\n",
        "        plt.plot([0 for _ in range(500)] + \n",
        "                 np.convolve(total_rewards, np.ones((500,))/500, mode=\"valid\").tolist())\n",
        "        plt.show()\n",
        "\n",
        "run(training_mode=True, pretrained=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "T4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "eeca14e5706a8cbd2ec783f43cd0237abd36936befa1c84d1d79f73d676a421c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
